# 📊 Project Databricks Products Analysis

Bem-vindo ao repositório **Project Databricks Products Analysis**, um projeto de análise exploratória e preparação de dados de produtos utilizando a plataforma **Databricks Community Edition** com **PySpark**! 🚀

<br>


## 🎯 Objetivo

O objetivo deste projeto é demonstrar, de forma prática, como realizar:

- 🔍 **Análise exploratória de dados (EDA)** de uma base de produtos
- 🧹 **Tratamento e preparação de dados** com PySpark
- 🛠️ Utilização de recursos do **Databricks Community Edition**
- 🧪 Criação de pipelines de dados simples e organizados

<br>


## 🧰 Ferramentas e Tecnologias

Este projeto utiliza as seguintes tecnologias e ferramentas:

| Ferramenta | Finalidade |
|-----------|------------|
| 💻 [Databricks Community Edition](https://community.cloud.databricks.com/) | Ambiente em nuvem para execução de notebooks com suporte a Spark |
| 🐍 Python 3 | Linguagem principal |
| 🔥 PySpark | Biblioteca para processamento distribuído |
| 📑 Apache Spark DataFrames | Estrutura de dados para análise eficiente |
| 📊 Matplotlib (integrado via display) | Visualizações simples |

<br>


## 📁 Estrutura do Projeto

O projeto é composto por **dois notebooks principais**, cada um com um propósito específico:

### 📘 1. `products-eda`
🔍 **EDA - Análise Exploratória de Dados de Produtos**

- Leitura da base de dados `.csv`
- Inspeção inicial dos dados: schema, tipos, primeiras linhas
- Estatísticas descritivas
- Detecção de valores ausentes
- Análise das colunas categóricas e numéricas
- Visualizações básicas com `display()`

> ✅ Ideal para entender a estrutura e a qualidade da base de dados de produtos antes da limpeza.

<br>


### 🧽 2. `products-cleaning`
🧼 **Limpeza e Preparação de Dados**

- Remoção de colunas desnecessárias
- Padronização de nomes e categorias
- Tratamento de valores nulos
- Conversão de tipos de dados
- Criação de novas colunas derivadas (ex: margem, categoria normalizada)
- Exportação do DataFrame final

> 🛠️ Este notebook prepara os dados para serem utilizados em análises posteriores, BI ou Machine Learning.

<br>


## 🧠 O que você aprende aqui?

- Fundamentos de uso do **Databricks** com Spark
- Manipulação e tratamento de dados com **PySpark**
- Construção de um fluxo de dados profissional
- Boas práticas em projetos de dados

<br>


## 🚀 Como usar

1. Crie uma conta gratuita no [Databricks Community Edition](https://community.cloud.databricks.com/)
2. Clone este repositório ou copie o conteúdo dos notebooks
3. Importe os notebooks para o Databricks
4. Faça o upload do dataset `products.csv` no Databricks File System (DBFS)
5. Execute os notebooks em ordem: `products-eda` ➡️ `products-cleaning`

<br>

<br>


## 👨‍💻 Expert

<p>
    <img 
      align=left 
      margin=10 
      width=80 
      src="https://avatars.githubusercontent.com/u/44624583?v=4"
    />
    <p>&nbsp&nbsp&nbspMarcos Winther<br>
    &nbsp&nbsp&nbsp
    <a href="https://github.com/MarcosWinther">
    GitHub</a>&nbsp;|&nbsp;
    <a href="https://www.linkedin.com/in/marcoswinthersilva/">LinkedIn</a>
    </p>
</p>
<br/><br/>

---

⌨️ com 💜 por [Marcos Winther](https://github.com/MarcosWinther)

<br>

## ⭐ Se você gostou, deixe uma estrela neste repositório!

Ajuda muito! 🌟

<br>

> “**Dados são o novo petróleo, mas precisam ser refinados para gerar valor.**” 🛢️➡️💡